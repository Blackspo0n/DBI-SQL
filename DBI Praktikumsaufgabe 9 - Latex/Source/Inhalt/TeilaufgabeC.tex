\section{Teilaufgabe C)}
\textbf{Versuchen Sie, die Laufzeit Ihres Programms zu beschleunigen! Dokumentieren Sie
einzelne Verbesserungsideen und die jeweiligen Laufzeitveränderungen für eine lokale
Ausführung Ihres Programms bei der Erzeugung einer 10-tps-Datenbank!}

\subsection{Transaktion}
\subsubsection*{Optimierung}
Um den Durchsatz der Daten zu erhöhen, lassen sich die Queries in einer
\textbf{Transaktion}\footnote{\url{https://docs.oracle.com/javase/tutorial/jdbc/basics/transactions.html}} zusammenfassen.  

Dazu muss die Option \textit{autoCommit} abgeschaltet werden und die Transaktion
mit einem manuellen \textit{commit} zum Server geschickt werden. Wir mussten
also unseren \hyperref[lst:tpsv2]{TpsCreator} erweitern, in
diesem legen wir dazu zwei neue Funktionen an:

\begin{lstlisting}[caption={Erweiterung der TpsCreator-Klasse}]
	public void beginTransaktion() {
		try {
			connection.databaseLink.setAutoCommit(false);
		} catch (SQLException e) {
			e.printStackTrace();
		}
	}
	
	public void endAndCommitTransaction() {
		try {
			connection.databaseLink.commit();
			connection.databaseLink.setAutoCommit(true);
		} catch (SQLException e) {
			e.printStackTrace();
		}
	}
\end{lstlisting}

Jetzt brauchen wir noch die Funktionalität, um die Funktionen aufzurufen. Damit
wir flexibel sind, haben wir hierfür ein Konsolen-Menü implementiert.
Dieses erstellt uns dann eine  \hyperref[lst:bmv2]{Benchmark}-Klasse, die der
\hyperref[lst:tpsv2]{TpsCreator}-Klasse alle nötigen Parameter übergibt und das Benchmarking ausführt.

\begin{lstlisting}[caption={Renderer für das Konsolen Menü}]
	public static int renderMenu() {
		System.out.println("======================- Benchmark Menu -===========================");
		System.out.println("= Wähle bitte eine der folgende Optionen:                         =");
		System.out.println("= (1) Benchmark, Debug Log, incl. drop & create                   =");
		System.out.println("= (2) Benchmark, Debug Log, excl. drop & create                   =");
		System.out.println("= (3) Benchmark, Debug Log, transactions, incl. drop & create     =");
		System.out.println("= (4) Benchmark, Debug Log, transactions, excl. drop & create     =");
		System.out.println("= (5) Benchmark, incl. drop & create                              =");
		System.out.println("= (6) Benchmark, excl. drop & create                              =");
		System.out.println("= (7) Benchmark, transactions, incl. drop & create                =");
		System.out.println("= (8) Benchmark, transactions, excl. drop & create                =");
		System.out.println("===================================================================");
		System.out.print("= Auswahl: ");
		
		return ConsoleReader.readInt();
	}
\end{lstlisting}

\subsubsection*{Bewertung}
Die Queries, die mittels einer Transaktion übertragen werden, werden bei
einer \textbf{10-tps-Datenbank} um \ca das \textbf{11fache} schneller als die
Queries die einzelnd zum Server geschickt werden. 

Wenn man in der JDBC Bibliothek mit großen Datenmengen arbeitet, lohnt es sich
performancemäßig dieses AutoCommit aus zu schalten. Der Nachteil, dass man eine
Transaktion selbst abschließen muss, ist gegenüber dem Performancegewinn eher zu
vernachlässigen.
\clearpage


\subsection{Schlüsselbedingungen}
\subsubsection*{Optimierung}
In den create-Statements befinden sich Schlüsselbedingungen für die Primär- und
Fremdschlüssel. Jeder Schlüssel erstellt auch einen sogenannten Index. Beim Einfügen
der Daten in die jeweiligen Tabellen ist so ein Index hinderlich, da anhand
dieser einige Bedingungen geprüft werden und somit wertvolle Sekunden im
Benchmarking kostet.

Entkapselt man also diese und fügt sie erst am Ende des Benchmark-Vorgangs
an, so braucht der Server diese Bedingungen nicht zu überprüfen. Wir müssen 
also eine Funktion schreiben, die am Ende jedes Benchmarks ausgeführt wird.
\begin{lstlisting}[caption={Alter Statements \& Funktion createKeys}]
	/**
	 * Alter Statements zum setzen der Keys
	 */
	
	public String[] AlterStatements = {
			"ALTER TABLE branches ADD PRIMARY KEY(branchid)",
			"ALTER TABLE accounts ADD PRIMARY KEY(accid)",
			"ALTER TABLE tellers ADD PRIMARY KEY(tellerid)",
			"ALTER TABLE accounts ADD  FOREIGN KEY(branchid) REFERENCES branches(branchid)",
			"ALTER TABLE tellers ADD  FOREIGN KEY(branchid) REFERENCES branches(branchid)",
			"ALTER TABLE history ADD  FOREIGN KEY(branchid) REFERENCES branches(branchid)",
			"ALTER TABLE history ADD  FOREIGN KEY(tellerid) REFERENCES tellers(tellerid)",
			"ALTER TABLE history ADD  FOREIGN KEY(accid) REFERENCES accounts(accid)"
	};
	
	/**
	 * Erstellt die Schlüasselbedingungen
	 * 
	 * @return Gibt an, ob win Fehler vorhanden ist.
	 */
	public boolean createKeys() {
	
		try {
			Statement statement = connection.databaseLink.createStatement();

			for (String table : this.AlterStatements) {
				statement.executeUpdate(table);
				if(isDebug) {
					System.out.println(table);
				}
			}

			return true;
		} catch (SQLException e) {
			System.out.println(e.getMessage());
			return false;
		}
	}
		
\end{lstlisting}

\subsubsection*{Bewertung}
Durch die entkapselung der Schlüsselbedingungen sparen wir im Benchmarking
einige Millisekunden. Insgesamt ist ein Performancezuwachs von 10 \% messbar. 
 
 Diese Handhabung der Schlüsselbedingungen sollte jedoch nicht in einem
 Produktivsystem verwendet werden, denn so hindert man das DBMS etwaige
 Optimierungen an dem Datenbestand vorzunehmen. Dies äußert sich in längeren
 Anfragezeiten gegenüber Datenbank.
\clearpage

\subsection{Implementierung des CopyManagers}
\subsubsection*{Optimierung}
Unser ausgewähltes DBMS PostgreSQL stellt ein \textbf{COPY}-Statement zur
Verfügung. Dieses Statement erlaubt uns Daten aus einer Textdatei oder aber auch
einer CSV Datei in unsere Datenbank zu importieren. 

Um dieses Feature zu nutzen, stellt der JDBC-Treiber von PostgreSQL eine
\textbf{CopyManager}\footnote{\url{https://jdbc.postgresql.org/documentation/publicapi/org/postgresql/copy/CopyManager.html}}-Klasse
zur Verfügung. Diesem Manager übergeben wir lediglich ein
\textbf{COPY}-Statement:

\begin{lstlisting}[caption={Initialisierung des CopyManagers},numbers=none]
CopyManager cpm = new CopyManager((BaseConnection) connection.databaseLink);

CopyIn ci = cpm.copyIn("COPY branches (branchid, branchname, balance, address) FROM STDIN WITH DELIMITER '|'");
\end{lstlisting}

Mit dem dadurch erzeugten \textbf{CopyIn}-Objekt ist es jetzt möglich dem CopyManager Daten zu
übergeben.
Das machen wir mittels der \textbf{writeToCopy}-Funktion:

\begin{lstlisting}[caption={WriteToCopy-Funktion},numbers=none]
ci.writeToCopy(sb.toString().getBytes(), 0, sb.length());
\end{lstlisting}

Nach Beendigung des \textbf{COPY}-Vorgangs, muss nur noch die Funktion
\textbf{endCopy} ausgeführt werden, um die Daten zum Server zu übertragen.

Nach Änderung create-Funktionen, in der Klasse
\hyperref[lst:tpsv2]{TpsCreator}, erhalten wir folgenden Code:

\begin{lstlisting}[caption={createAccountTupel mit CopyManager}]
	/**
	 * Erstellt die Tupel in der Tabelle Accounts
	 * 
	 * @param n Anzahl der Tupel, die erstellt werden mal 10000
	 * @return Gibt an, ob ein Fehler vorhanden ist
	 */
	public boolean createAccountTupel(int n) {
		int localConst = n*10000;
		try {
			CopyManager cpm = new CopyManager((BaseConnection) connection.databaseLink);
			CopyIn ci = cpm.copyIn("COPY accounts(accid, NAME, balance, address, branchid) FROM STDIN WITH DELIMITER '|'");
			
			for (int i = 1; i <= localConst; i++) {
				StringBuilder sb = new StringBuilder("|aaaaaaaaaaaaaaaaaaaa|0|aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa|").append(
						ThreadLocalRandom.current().nextInt(1, n + 1)
				).append("\n").insert(0, i);
				
				ci.writeToCopy(sb.toString().getBytes(), 0, sb.length());
				
				if(isDebug) {
					System.out.print(sb.toString());
				}
			}
	        ci.endCopy();			
			return true;
		} catch (SQLException e) {
			e.printStackTrace();
		}
		
		return false;
	}
\end{lstlisting}

Da bei dieser Variante viel mit Strings gearbeitet wird, erweist sich der Einsatz eines 
Stringbuilders als effektiv, anstatt der üblichen Verkettung, da der StringBuilder wesentlich 
performanter arbeitet als die Verkettung von Datentypen.

\subsubsection*{Bewertung}
Das \textbf{COPY}-Statement ist dank seiner starken Spezialisierung auf den
Anwendungszwecks um einiges schneller als die ansich schon schnellen
\textit{PreparedStatements}.

In Verbindung mit dem in JDBC-Treiber zur Verfügung stehenden CopyManagers,
erlaubt uns das bei einer \textbf{10-tps-Datenbank} ein Benchmarkergebnis von
2500 Millisekunden. Damit sind wir um das \textbf{36fache} schneller als in der
ursprünglichen Version.

Selbst Datenbank-Größen jenseits $n > 50$ laufen binnen weniger Sekunden
problemlos durch.
\clearpage


\subsection{Optimierungseinstellungen im DBMS}
\subsubsection*{Optimierung}
Um ein noch besseres Eregbnis zu erzielen kann man in PostgreSQL die
\textit{asyncronen Commits} aktivieren. Diese sind standardmäßig deaktiviert
und müssen in der Konfigurationsdatei von PostgreSQL erst einmal aktiviert
werden\footnote{\url{https://www.postgresql.org/docs/current/static/wal-async-commit.html}}.

Unter Unix-Systemen liegt die Konfigurationsdatei, meistens unter \newline
\gqq{\textit{/etc/postgresql/\{versionsnummer\}/main/postgresql.conf}}

Aktivierte \& geänderte Serverkonfiguration:
\begin{lstlisting}[title={Veränderte Serverkonfiguration}]
shared_buffers		= 1GB

#wal-writer Engine
synchronous_commit	= off
commit_delay		= 50000
wal_writer_delay	= 5000ms
wal_buffers			= 128MB
\end{lstlisting}

\textbf{shared\_buffer} beschreibt, wie viel Ram der Server belegen darf.
Standardmäßig steht dieser Wert auf 128MB. Erhöht man diesen Wert, erhöht
sich der Durchsatz der Daten maginal. Ein guter Wert ist $1/4$ des
Server-Rams. In unseren Fall ist das dementsprechend 1GB.

Die \gqq{wal-writer}-Engine ist dafür verantwortlich, wie die Daten auf die
Festplatte geschrieben werden. Der hohe \textbf{delay}-Wert beispielsweise, sorgt
dafür, dass das Datenbanksystem nur alle 5 Sekunden 128MB auf die Festplatte
schreiben darf. So zwingen wir unser DBMS vieles im Ram zu verwalten, was
wesentlich performanter ist, da der Ram sehr geringe Zugriffszeiten besitzt. Wir
laufen aber im Fehlerfall Gefahr Daten zu verlieren.

\subsubsection*{Bewertung}
Der schlussendliche Performanceschub fällt je nach System unterschiedlich aus.
So hat diese Konfiguration auf den Laptop eines Kommilitonen eine Einsparung von 100
Millisekunden bei einer \textbf{10-tps-Datenbank} eingebracht.

\clearpage

% \subsection{Adressauflösung von Domainnamen}
% \subsubsection*{Optimierung}
% Um das Ergebnis noch mehr zu verbessern kommt nun das Feintuning. Dazu
% haben wir uns jetzt nicht das DBMS zugewendet, sondern haben uns auf die
% Netzwerkebene begeben.
% 
% Eine Datenbank spricht man normalerweiße mit einer Domain an. 
% Eine Domain muss aber erst einmal aufgelöst werden.
% Das ist ein massiver Nachteil gegenüber der herkömmlicher IP. Jeder
% DNS-Server \bzw DNS-Cache muss in irgendeiner Tabelle nachschauen, welche Domain
% zu welcher IP gehört. Das kostet beim Verbindungsaufbau wertvolle Zeit.
% 
% Selbst der lokale DNS-Cache muss dies \zB für \textbf{localhost} machen.
% Möchten wir also die Zugriffszeiten umgehen, brauchen wir einfach nur die IP-Adresse
% statt des Domainnamens einzugeben. Dies wäre für \textbf{localhost} entweder \gqq{127.0.0.1} als
% IPv4-Schreibweiße oder \gqq{[::1]} als IPv6 Schreibweise.
% 
% \subsubsection*{Bewertung}
% In unserem Programm setzten wir 
% Wir haben in unser Programm deswegen nur IP-Adressen verwendet um sicher zu gehen, dass wir 
% die Zugriffszeiten umgegehen. Einen Performanceschub im
% Benchmark bringt diese Optimierung nicht wirklich.

\subsection{Gesamter Performancezuwachs}
Durch das schrittweise Optimieren des Programmcodes konnte ein betrachtlicher
Performancezuwachs erzielt werden. Zwar ist es in der Praxis nicht immer möglich
jede der hier aufgeführten Optimierungen zu nutzen, doch es zeigt was möglich
ist, wenn man sich mit den jeweiligen Datenbanken und Datenbanktreibern beschäftigt.

Die folgende Tabelle zeigt den Performancezuwachs prozentual zur unoptimierten
Programmversion an einer \textbf{10-tps-Datenbank}: 


\tabelle{Leistungszuwachs
durch Optimierungen}{tab:Zuwachs}{Zuwachs.tex}

\clearpage