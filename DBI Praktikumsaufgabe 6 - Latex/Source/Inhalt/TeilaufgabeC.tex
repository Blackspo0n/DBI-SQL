\section{Teilaufgabe C)}
\textbf{Versuchen Sie, die Laufzeit Ihres Programms zu beschleunigen! Dokumentieren Sie
einzelne Verbesserungsideen und die jeweiligen Laufzeitveränderungen für eine lokale
Ausführung Ihres Programms bei der Erzeugung einer 10-tps-Datenbank!}

\subsection{Transaktion}
Um den Durchsatz der Daten zu erhöhen, lassen sich die Queries in einer
\textbf{Transaktion}\footnote{\url{https://docs.oracle.com/javase/tutorial/jdbc/basics/transactions.html}} zusammenfassen.  

Dazu muss die Option \textit{autoCommit} abgeschaltet werden und die Transaktion
mit einem manuellen \textit{commit} zum Server geschickt werden. Wir mussten
also unseren \hyperref[lst:tpsv2]{TpsCreator} erweitern. In
dieser legen wir dazu 2 neue Funktionen an:

\begin{lstlisting}[caption={Erweiterung der TpsCreator-Klasse}]
	public void beginTransaktion() {
		try {
			connection.databaseLink.setAutoCommit(false);
		} catch (SQLException e) {
			e.printStackTrace();
		}
	}
	
	public void endAndCommitTransaction() {
		try {
			connection.databaseLink.commit();
			connection.databaseLink.setAutoCommit(true);
		} catch (SQLException e) {
			e.printStackTrace();
		}
	}
\end{lstlisting}

Jetzt brauchen wir noch die Funktionalität, um die Funktionen aufzurufen. Damit
wir recht flexibel sind haben wir hierfür ein Konsolen-Menü implementiert.
Dieses erstellt uns dann eine  \hyperref[lst:bmv2]{Benchmark}-Klasse, die der
\hyperref[lst:tpsv2]{TpsCreator}-Klasse alle nötigen Parameter übergibt und das Benchmarking ausführt.\\

\begin{lstlisting}[caption={Renderer für das Konsolen Menü}]
	public static int renderMenu() {
		System.out.println("======================- Benchmark Menu -===========================");
		System.out.println("= Wähle bitte eine der folgende Optionen:                         =");
		System.out.println("= (1) Benchmark, Debug Log, incl. drop & create                   =");
		System.out.println("= (2) Benchmark, Debug Log, excl. drop & create                   =");
		System.out.println("= (3) Benchmark, Debug Log, transactions, incl. drop & create     =");
		System.out.println("= (4) Benchmark, Debug Log, transactions, excl. drop & create     =");
		System.out.println("= (5) Benchmark, incl. drop & create                              =");
		System.out.println("= (6) Benchmark, excl. drop & create                              =");
		System.out.println("= (7) Benchmark, transactions, incl. drop & create                =");
		System.out.println("= (8) Benchmark, transactions, excl. drop & create                =");
		System.out.println("===================================================================");
		System.out.print("= Auswahl: ");
		
		return ConsoleReader.readInt();
	}
\end{lstlisting}

 
Die Queries, die mittels einer Transaktion übertragen worden sind, sind bei
einer \textbf{10-tps-Datenbank} um \ca das \textbf{11fache} schneller als die
Queries die einzelnd zum Server geschickt werden.

\begin{figure}[!htbp] 
    \subfigure[mit
    Transactions]{\includegraphics[width=0.49\textwidth]{Bilder/Auswahl_015.png}}
    \subfigure[ohne
    Transaction]{\includegraphics[width=0.49\textwidth]{Bilder/Auswahl_014.png}}
\end{figure} 


\subsection{Prepared Statements}
Selbst in einer Transaktion wird jeder einzelne Query validiert. Wir besitzen
nun aber eine Masse von gleich strukturierten Statements. Jeden einzelnen zu
validieren kostet den Server Zeit und Ressourcen.
 
Wir haben also eine Möglichkeit gesucht eine vorher definierte und validierte
Struktur eines Queries zu bekommen. Dazu hat sich das Konstrukt 
\textbf{Prepared Statement}\footnote{\url{https://docs.oracle.com/javase/tutorial/jdbc/basics/prepared.html}} angeboten.
 
Wie der Name schon sagt, wird der Query im Prepared Stament einmal zum Server
geschickt und validiert. Anschließend kann man mit der Referenz
schnell und sicher die Daten dem Server übergeben.
 
Die umgeschriebene Funktion in der \hyperref[lst:tpsv2]{TpsCreator}-Klasse für
Accounts sieht nun folgendermaßen aus:
 \begin{lstlisting}[caption={Einbinden von Prepared Statements}]

	public boolean createAccountTupel(int n) {
		int localConst = n*10000;
		int localRandom;		
		try {
			PreparedStatement insertBranches = connection.databaseLink.prepareStatement("INSERT INTO accounts (accid, NAME, balance, address, branchid) VALUES(?, 'account', 0,'test', ?)");
			
			for (int i = 1; i <= localConst; i++) {
				localRandom = ThreadLocalRandom.current().nextInt(1, n + 1);
				insertBranches.setInt(1, i);
				insertBranches.setInt(2, localRandom);
				insertBranches.addBatch();
				
				if(isDebug) {
					System.out.println("INSERT INTO branches (branchid, branchname, balance,address) VALUES(" + i + ", 'branch', 0, 'branch')");
				}
			}

			insertBranches.executeBatch();
			return true;
		} catch (SQLException e) {
			e.printStackTrace();
		}
		return false;
	}
 \end{lstlisting}

Eine gute Eigenschaft von den Prepared Statements ist, dass sie die
Transaktionsverwaltung schon besitzen und damit bei gleichen Queries
deutlich schneller sind als ein normales Statement, welches ein und den selben
Query immer und immer wieder ausführt. Diese Eigenschaft besitzt ein
Prepared Statement auch, wenn das Feature \textit{autoCommit} aktiviert ist.

Um aber aussagekräftige Benchmarks zu erhalten, ist gerade das Feature
hinderlich, Wir möchten ja die Queries auch ohne Transaktion ausführen können,
deshalb müssen wir uns eine alte \gqq{Kopie} der Klasse behalten und bei Bedarf
instanziieren. Dafür legen wir ein Interface an, welches von der neuen Klasse
\hyperref[lst:tpsv2]{TpsCreator} und der alten Klasse
\hyperref[lst:tpsoldv2]{TpsCreatorOldStatements} implementiert wird.
Anschließend fragen wir in der \hyperref[lst:mainv2]{Main}-Klasse den
Nutzer, welche Version er verwenden möchte.


\begin{center}
\includegraphics[scale=0.8]{Bilder/Auswahl_016.png}
\end{center}
Mit den Prepared Statement ist unser Benchmark jetzt \textbf{36fach} schneller
als mit unserem ursprüngliches Benchmark-Tool, welches nur mit normalen
Statements lief.

\subsection{IDs vom Server generieren lassen}
Momentan benutzen wir die Ressourcen von unserem Javaprogramm um uns eine
zufällige ID zu generieren. Da wir aber so viel wie möglich vom Server
verarbeiten lassen wollen, lagern wir das Generieren der IDs auf unseren Server
aus, denn dieser hat mit Sicherheit die Möglichkeit aus unserem SQL-Query etwas
Effizentes zu generieren.

Wir bedienen uns also den Zufallszahlengenerator von PostgreSQL um uns
eine ID zu genrieren.
\begin{lstlisting}[language=sql]
SELECT rand();
\end{lstlisting}

Diese Funktion liefert uns eine Gleitkommazahl zwischen 0 und 1. Diese Zahl
müssten wir anschließend nur noch $ \cdot  n + 1 $ rechnen um eine zufällige ID
zwischen 1 und $n$ zu erzeugen. Das am Ende stehende $ + 1$ soll dafür sorgen,
dass $n$ auch generiert werden kann. Diese Zahl muss anschließend mittels der
Funktion \textit{trunc} in ein Integer gecastet werden.

Unser Query, der uns die IDs generiert, sieht dann folgendermaßen aus:
\begin{lstlisting}[language=sql]
SELECT trunc(random() *  n  + 1);
\end{lstlisting}

Diesen Query können wir jetzt auf unser Prepared Statement anwenden:
\begin{lstlisting}[language=sql, caption={INSERT-Query mit vom Server
generierten ID}]
INSERT INTO accounts (accid, NAME, balance, address, branchid) VALUES(?, 'account', 0,'test', trunc(random() * n + 1))
\end{lstlisting}

Diese Optimierung hat uns bei einer \textbf{10-tps-Datenbank} nochmal \ca
500 Millisekunden gespart. Somit sind wir jetzt \textbf{38fach} schneller 
als mit dem Benchmark-Tool, welches wir als erstes entwickelt hatten.

--- vergleich rein machen

\subsection{Ändern der Servereinstellungen}

Um ein noch besseres Eregbnis zu erzielen kann man in PostgreSQL die
\textit{asyncronen Commits} aktivieren. Diese sind Stanardmäßig dieaktiviert und
müssen in der Konfigurationsdatei von PostgreSQL ersteinmal aktiviert werden\footnote{https://www.postgresql.org/docs/current/static/wal-async-commit.html}.

Unter Unix-Systemen liegt die Konfigurationsdatei meistens unter \newline
\gqq{\textit{/etc/postgresql/\{versionsnummer\}/main/postgresql.conf}}

Aktivierte \& geänderte Serverkonfiguration:
\begin{lstlisting}[title={Veränderte Serverkonfiguration}]
shared_buffers		= 1GB
synchronous_commit	= off
wal_writer_delay	= 5000ms
commit_delay		= 50000
wal_buffers			= 128MB
\end{lstlisting}

Der Performanceschub fällt je nach System unterschiedlich aus. So hat diese
Konfiguration auf den Laptop eines Kommilitonen ein 100 Millisekunden bei einer
\textbf{10-tps-Datenbank} ausgemacht.

\subsection{Adressauflösung von Domainnamen}
Um das Ergebnis noch mehr zu verbessern kommt nun das Feintuning. Dazu
haben wir uns jetzt nicht das DBMS zugewendet, sondern haben uns auf die
Netzwerkebene begeben.

Eine Datenbank spricht man normalerweiße mit einer Domain an. 
Eine Domain muss aber erst einmal aufgelöst werden.
Das ist ein massiver Nachteil gegenüber der herkömmlicher IP. Jeder
DNS-Server \bzw DNS-Cache muss in irgendeiner Tabelle nachschauen, welche Domain
zu welcher IP gehört. Das kostet beim Verbindungsaufbau wertvolle Zeit.

Selbst der lokale DNS-Cache muss dies \zB für \textbf{localhost} machen.
Möchten wir also die Zugriffszeiten umgehen, brauchen wir einfach nur die IP-Adresse
statt des Domainnamens einzugeben. Dies wäre für \textbf{localhost} entweder \gqq{127.0.0.1} als
IPv4-Schreibweiße oder \gqq{[::1]} als IPv6 Schreibweise.

Wir haben in unser Programm deswegen nur IP-Adressen verwendet um sicher zu gehen, dass wir 
die Zugriffszeiten umgegehen.
\clearpage